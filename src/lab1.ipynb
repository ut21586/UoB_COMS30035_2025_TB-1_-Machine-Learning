{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d5fc9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import necessary libraries \u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# https://github.com/uob-COMS30035/lab_sheets_public/blob/main/lab1/lab1-intro_to_numpy_scikitlearn.ipynb\n",
    "# Import necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "\n",
    "from skimage import io\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Declare two 2D matrices A and B.\n",
    "A = np.array([[2, 3], [4, -1], [5, 6]])\n",
    "B = np.array([[5, 2], [8, 9], [2, 1]])\n",
    "\n",
    "# Using operation to calculate multiplication, application, dot product and hadamard.\n",
    "# Print out all result.\n",
    "C1 = 3 * A\n",
    "C2 = A + B\n",
    "C3 = A @ B.T\n",
    "C4 = A * B\n",
    "\n",
    "print(\"C1 =\\n\", C1)\n",
    "print(\"C2 =\\n\", C2)\n",
    "print(\"C3 =\\n\", C3)\n",
    "print(\"C4 =\\n\", C4)\n",
    "\n",
    "# Calculate now the sum, mean, and variance of the matrix.\n",
    "# Print out all result.\n",
    "sum_A = np.sum(A)       # sum\n",
    "mean_A = np.mean(A)     # mean\n",
    "var_A = np.var(A)       # variance\n",
    "\n",
    "print(\"sum:\", sum_A)\n",
    "print(\"mean:\", mean_A)\n",
    "print(\"variance:\", var_A)\n",
    "\n",
    "# Afterwards, calculate the sum of the rows and then the columns of A. Hint, specify the parameter axis.\n",
    "col_sum = np.sum(A, axis=0) # Sum of all columns.\n",
    "row_sum = np.sum(A, axis=1) # SUm of all row.\n",
    "print(\"Sum of columns:\", col_sum)  # output seems like [a, b]\n",
    "print(\"Sum of rows:\", row_sum)     # output seems like [a, b, c]\n",
    "\n",
    "# Declare sigmoid funciton.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Calculate sigmoid of array A.\n",
    "A = np.array([-5, 0, 5])\n",
    "print(sigmoid(A))\n",
    "\n",
    "# Plot the sigmoid function within the interval [−5,5].\n",
    "# With range of [-5, 5] averagly make 100 plots\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Sigmoid Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"sigmoid(x)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# \n",
    "def standardiseCols(x):\n",
    "    mean = np.mean(x, axis=0)\n",
    "    std = np.std(x, axis=0, ddof=0)\n",
    "    return (x - mean) / std\n",
    "\n",
    "x = np.array([\n",
    "    [0, 3, 5],\n",
    "    [1, 6, 4],\n",
    "    [3, -2, 8],\n",
    "    [-1, 1, 10]\n",
    "])\n",
    "\n",
    "x_std = standardiseCols(x)\n",
    "print(\"standardised: \\n\", x_std)\n",
    "print(\"mean for each column: \", np.mean(x_std, axis=0))\n",
    "print(\"standard deviation for each column: \", np.std(x_std, axis=0, ddof=0))\n",
    "\n",
    "# Reshaping numpy arrays.\n",
    "# Read png and show shape\n",
    "image = io.imread('flower.png')\n",
    "io.imshow(image)\n",
    "print(\"original shape:\", image.shape)\n",
    "\n",
    "# take 3D png array reshape as (length*height*3, 1) vector.\n",
    "v = image.reshape(-1, 1)\n",
    "print(\"reshaped vector shape:\", v.shape)\n",
    "a = np.arange(5)\n",
    "\n",
    "print(a)\n",
    "print(\"a.shape:\", a.shape)\n",
    "print(\"a.T:\", a.T)\n",
    "print(\"a.T.shape:\", a.T.shape)\n",
    "\n",
    "# Transfer 1-D array into 2-D arry.\n",
    "# Switching the scalars of vector.\n",
    "a = a.reshape(1,-1) # For row of 2-D array\n",
    "print(a)\n",
    "a.shape\n",
    "\n",
    "a = a.reshape(-1,1) # For colomn of 2-D array.\n",
    "print(a)\n",
    "a.shape\n",
    "\n",
    "assert(a.shape == (5,1)) # Check dimension.\n",
    "\n",
    "\n",
    "# Scikit\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load California housing prize as DataFrame.\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "df = housing.frame\n",
    "\n",
    "# Use Seaborn scatch pairplot\n",
    "sns.pairplot(df)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Standardise the California housing training dataset.\n",
    "\n",
    "# Load california housing data.\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "X = df.drop(columns=['MedHouseVal'])\n",
    "\n",
    "# standarlization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# turn back DataFrame.\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# checking\n",
    "means = X_scaled_df.mean()\n",
    "stds = X_scaled_df.std()\n",
    "\n",
    "print(\"mean after standarlisation: \")\n",
    "print(means)\n",
    "print(\"standard deviation: \")\n",
    "print(stds)\n",
    "\n",
    "\"\"\"\n",
    "Employ train_test_split to partition the standardised California house price dataset into a 70% training set and 30% test set;\n",
    "\n",
    "Count the number of samples in the training and test sets;\n",
    "\n",
    "Indicate whether the random_state parameter should be set, and explain the rationale;\n",
    "\n",
    "Briefly outline the purpose of cross-validation (to prevent overfitting in the test set and enhance model generalisation capability).\n",
    "\"\"\"\n",
    "# Loading data\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "# Seperate characteric and target.\n",
    "X = df.drop(columns=['MedHouseVal'])\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "# Characteristic Standard.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Seperate training set and testing set 70%/30%. random_state used to check result.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Calculate sample population.\n",
    "print('training set sample population:', X_train.shape[0])\n",
    "print('testing set sample population:', X_test.shape[0])\n",
    "\n",
    "\"\"\"\n",
    "Training set sample size = 70% × 20,640 ≈ 14,448;\n",
    "Test set sample size = 30% × 20,640 ≈ 6,192.\n",
    "\n",
    "It is recommended to set the random_state parameter to ensure consistent partitioning results across multiple runs, facilitating result reproducibility and comparison.\n",
    "\n",
    "Cross-validation is a technique to further enhance a model's generalisation capability. It involves dividing the training set into multiple “folds”, performing multiple rounds of training and validation, and is used to adjust hyperparameters.\n",
    "\"\"\"\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Linear regression: \", model.coef_)\n",
    "print(\"intercept term: \", model.intercept_)\n",
    "\n",
    "# Predict on training and test sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(\"Training RMSE:\", rmse_train)\n",
    "print(\"Test RMSE:\", rmse_test)\n",
    "\n",
    "# Plot predictions vs real values for test data\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('Test set predictions vs true values')\n",
    "plt.show()\n",
    "\n",
    "# Linear models for regression。\n",
    "\n",
    "# Load California housing dataset\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "df = housing.frame\n",
    "\n",
    "# Prepare design matrix X with bias term\n",
    "X = df.drop(columns='MedHouseVal')\n",
    "X.insert(0, 'bias', 1)  # Add column of ones for bias\n",
    "\n",
    "# Output vector y\n",
    "y = df['MedHouseVal'].values\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = X.values\n",
    "\n",
    "# Compute weights by closed-form OLS solution\n",
    "w = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "print('Weights vector including bias:', w)\n",
    "\n",
    "# Least-Squares Fitting.\n",
    "np.random.seed(0)\n",
    "N = 30\n",
    "sigma = 5\n",
    "x = np.sort(np.random.sample((N,1))) * 10\n",
    "y = (x-1)*(x-5) + np.random.normal(0, sigma, N).reshape(-1, 1)\n",
    "\n",
    "# Add bias column to X\n",
    "X_bias = np.concatenate([np.ones_like(x), x], axis=1)\n",
    "\n",
    "# Least squares solution\n",
    "w, _, _, _ = np.linalg.lstsq(X_bias, y, rcond=None)\n",
    "y_pred = X_bias @ w\n",
    "\n",
    "# Plot\n",
    "plt.scatter(x, y, label='Data')\n",
    "plt.plot(x, y_pred, color='red', label='Fitted line')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Slope (w1):', w[1][0])\n",
    "print('Intercept (b):', w[0][0])\n",
    "\n",
    "# Non-linear Regression: Polynomial Fitting.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(x)\n",
    "model = LinearRegression().fit(X_poly, y)\n",
    "y_poly_pred = model.predict(X_poly)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_poly_pred, color='red')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMS30035_labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
